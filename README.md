# Ikshana - AI-Powered Visual Aid

## ğŸŒŸ Introduction
**Ikshana** is an AI-integrated assistive technology designed for visually impaired individuals. It utilizes a webcam to capture real-world images, analyze text within them, and read aloud the translated content using advanced AI models. 

## ğŸ› ï¸ Features
- ğŸ“· **Real-time image capture** via webcam
- ğŸ§  **AI-based text detection & translation** from various languages
- ğŸ”Š **Text-to-Speech (TTS) integration** for spoken output
- âš¡ **Lightweight and efficient** implementation using modern AI libraries

## ğŸš€ Tech Stack
- **Programming Language:** Python
- **Frameworks/Libraries:** OpenCV, Tesseract OCR, SpeechRecognition, gTTS, Flask
- **AI Model:** ChatGPT for natural language processing

## ğŸ”§ Installation & Setup
1. Clone the repository & follow the below mentioned steps:
   ```bash
   git clone https://github.com/yourusername/ikshana.git
   cd ikshana
2. Install dependencies:
   ```bash
   pip3 install -r requirements.txt
3ï¸. Set Up API Keys
ğŸ‘‰ Google Gemini API Key (For Image Processing)
   Go to Google AI Studio and sign in.
   Navigate to the API Keys section.
   Generate a new API key.
   Copy the API key and insert it into the genai.configure(api_key="YOUR_API_KEY") line in Main.py.
   
   
ğŸ“· Usage
Start the application and allow webcam access.
Position text in front of the camera.
The AI detects, translates (if needed), and reads aloud the text.
ğŸ’¡ Future Enhancements
ğŸ” Improved text detection accuracy
ğŸŒ Support for more languages and dialects
ğŸ“¡ Integration with IoT devices for standalone operation
ğŸ¤ Contributing
Contributions are welcome! Feel free to fork the repository, submit pull requests, or suggest improvements.

